# src/calibration/calibration_engine.py

import pandas as pd
import numpy as np
import crnpy
from scipy.optimize import minimize
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
import json

from ..core.logger import CRNPLogger, ProcessTimer
from ..utils.file_handler import FileHandler
from .neutron_correction import NeutronCorrector


class CalibrationEngine:
    """CRNP ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ë‹´ë‹¹í•˜ëŠ” ì—”ì§„ í´ë˜ìŠ¤"""
    
    def __init__(self, station_config: Dict, processing_config: Dict, 
                 logger: Optional[CRNPLogger] = None):
        self.station_config = station_config
        self.processing_config = processing_config
        self.logger = logger or CRNPLogger("CalibrationEngine")
        
        # ì¢…ì† ëª¨ë“ˆ ì´ˆê¸°í™”
        self.file_handler = FileHandler(self.logger)
        self.neutron_corrector = NeutronCorrector(station_config, processing_config, self.logger)
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì •
        self.calibration_config = self.processing_config.get('calibration', {})
        self.depths = self.calibration_config.get('reference_depths', [10, 30, 60])
        self.weighting_method = self.calibration_config.get('weighting_method', 'Schron_2017')
        self.optimization_method = self.calibration_config.get('optimization_method', 'Nelder-Mead')
        self.initial_N0 = self.calibration_config.get('initial_N0', 1000)
        
        # í† ì–‘ íŠ¹ì„±
        soil_props = self.station_config.get('soil_properties', {})
        self.bulk_density = soil_props.get('bulk_density', 1.44)
        self.clay_content = soil_props.get('clay_content', 0.35)
        self.lattice_water = None  # ìë™ ê³„ì‚°
        
    def run_calibration(self, calibration_start: str, calibration_end: str,
                       fdr_data_path: str, crnp_data_path: str,
                       output_dir: str) -> Dict[str, Any]:
        """ì „ì²´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        
        with ProcessTimer(self.logger, "CRNP Calibration",
                         period=f"{calibration_start} to {calibration_end}"):
            
            try:
                # 1. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê¸°ê°„ ì„¤ì •
                cal_start = pd.to_datetime(calibration_start)
                cal_end = pd.to_datetime(calibration_end)
                
                # 2. ë°ì´í„° ë¡œë“œ
                fdr_data, crnp_data = self._load_calibration_data(
                    fdr_data_path, crnp_data_path, cal_start, cal_end
                )
                
                # 3. ì¤‘ì„±ì ë³´ì • ì ìš©
                corrected_crnp = self._apply_neutron_corrections(crnp_data)
                
                # 4. ì¼ë³„ ë°ì´í„° ë§¤ì¹­
                matched_data = self._match_daily_data(fdr_data, corrected_crnp, cal_start, cal_end)
                
                # 5. N0 ìµœì í™”
                optimization_result = self._optimize_N0(matched_data)
                
                # 6. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ìƒì„±
                calibration_result = self._create_calibration_result(
                    optimization_result, corrected_crnp, cal_start, cal_end
                )
                
                # 7. ê²°ê³¼ ì €ì¥
                self._save_calibration_results(calibration_result, output_dir)
                
                self.logger.info(f"Calibration completed successfully. N0 = {calibration_result['N0_rdt']:.2f}")
                return calibration_result
                
            except Exception as e:
                self.logger.log_error_with_context(e, "Calibration process")
                raise
                
    def _load_calibration_data(self, fdr_path: str, crnp_path: str,
                                cal_start: datetime, cal_end: datetime) -> Tuple[pd.DataFrame, pd.DataFrame]:
            """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ - ìˆ˜ì •ëœ ë²„ì „"""
            
            with ProcessTimer(self.logger, "Loading calibration data"):
                
                # FDR ë°ì´í„° ë¡œë“œ
                self.logger.info(f"Loading FDR data from {fdr_path}")
                fdr_data = pd.read_excel(fdr_path)
                
                # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
                if 'Date' in fdr_data.columns:
                    fdr_data['Date'] = pd.to_datetime(fdr_data['Date'])
                else:
                    raise ValueError("Date column not found in FDR data")
                    
                # CRNP ë°ì´í„° ë¡œë“œ - ìˆ˜ì •ëœ ë¶€ë¶„!
                self.logger.info(f"Loading CRNP data from {crnp_path}")
                
                # ì „ì²˜ë¦¬ëœ íŒŒì¼ì€ ì´ë¯¸ í—¤ë”ê°€ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì½ê¸°
                crnp_data = pd.read_excel(crnp_path)
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ ì»¬ëŸ¼ í™•ì¸ ë° ì²˜ë¦¬
                if 'timestamp' in crnp_data.columns:
                    # ì´ë¯¸ ì „ì²˜ë¦¬ì—ì„œ timestamp ì»¬ëŸ¼ì´ ìƒì„±ë˜ì—ˆìŒ
                    self.logger.info("Using existing timestamp column")
                    pass  # ê·¸ëŒ€ë¡œ ì‚¬ìš©
                elif 'Timestamp' in crnp_data.columns:
                    # Timestamp ì»¬ëŸ¼ë§Œ ìˆëŠ” ê²½ìš° timestampë¡œ ë³µì‚¬
                    crnp_data['timestamp'] = pd.to_datetime(crnp_data['Timestamp'], errors='coerce')
                else:
                    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ íƒ€ì„ìŠ¤íƒ¬í”„ì¼ ê°€ëŠ¥ì„±
                    first_col = crnp_data.columns[0]
                    crnp_data['timestamp'] = pd.to_datetime(crnp_data[first_col], errors='coerce')
                    self.logger.warning(f"Using first column as timestamp: {first_col}")
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ ìœ íš¨ì„± í™•ì¸
                valid_timestamps = crnp_data['timestamp'].notna().sum()
                self.logger.info(f"Valid timestamps in CRNP data: {valid_timestamps}/{len(crnp_data)}")
                
                if valid_timestamps == 0:
                    raise ValueError("No valid timestamps found in CRNP data")
                
                # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§
                fdr_mask = (fdr_data['Date'] >= cal_start) & (fdr_data['Date'] <= cal_end)
                crnp_mask = (crnp_data['timestamp'] >= cal_start) & (crnp_data['timestamp'] <= cal_end)
                
                fdr_filtered = fdr_data[fdr_mask].copy()
                crnp_filtered = crnp_data[crnp_mask].copy()
                
                self.logger.log_data_summary("FDR_Calibration", len(fdr_filtered))
                self.logger.log_data_summary("CRNP_Calibration", len(crnp_filtered))
                
                # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
                if len(crnp_filtered) == 0:
                    self.logger.error("âš ï¸ CRNP calibration data is empty!")
                    self.logger.error(f"CRNP data range: {crnp_data['timestamp'].min()} to {crnp_data['timestamp'].max()}")
                    self.logger.error(f"Calibration range: {cal_start} to {cal_end}")
                    self.logger.error(f"Available CRNP columns: {list(crnp_data.columns)}")
                    
                    # ì¤‘ì„±ì ì¹´ìš´íŠ¸ í™•ì¸
                    if 'N_counts' in crnp_data.columns:
                        neutron_valid = crnp_data['N_counts'].notna().sum()
                        self.logger.error(f"Neutron counts available: {neutron_valid}/{len(crnp_data)}")
                    else:
                        self.logger.error("N_counts column not found!")
                        
                    # ê¸°ê°„ ë‚´ ë°ì´í„° ì¬í™•ì¸
                    period_data = crnp_data[crnp_mask]
                    self.logger.error(f"Period data count: {len(period_data)}")
                    
                else:
                    # ì¤‘ì„±ì ì¹´ìš´íŠ¸ í™•ì¸
                    if 'N_counts' in crnp_filtered.columns:
                        neutron_valid = crnp_filtered['N_counts'].notna().sum()
                        self.logger.info(f"Neutron counts in calibration period: {neutron_valid}/{len(crnp_filtered)}")
                        
                        if neutron_valid == 0:
                            self.logger.warning("No valid neutron counts in calibration period!")
                
                return fdr_filtered, crnp_filtered
            
    def _apply_neutron_corrections(self, crnp_data: pd.DataFrame) -> pd.DataFrame:
        """ì¤‘ì„±ì ë³´ì • ì ìš©"""
        
        with ProcessTimer(self.logger, "Applying neutron corrections"):
            
            # ì›ì‹œ ì¤‘ì„±ì ì¹´ìš´íŠ¸ ì„¤ì •
            crnp_data['total_raw_counts'] = crnp_data['N_counts']
            
            # ì¤‘ì„±ì ë³´ì • ì ìš©
            corrected_data = self.neutron_corrector.apply_corrections(crnp_data)
            
            # ì´ìƒê°’ ì œê±°
            cleaned_data = self.neutron_corrector.remove_outliers(
                corrected_data, 'total_corrected_neutrons', threshold=3.0
            )
            
            return cleaned_data
            
    def _match_daily_data(self, fdr_data: pd.DataFrame, crnp_data: pd.DataFrame,
                        cal_start: datetime, cal_end: datetime) -> pd.DataFrame:
        """ì¼ë³„ FDRê³¼ CRNP ë°ì´í„° ë§¤ì¹­ - ìµœì¢… ìˆ˜ì • ë²„ì „"""
        
        with ProcessTimer(self.logger, "Matching daily data"):
            
            # 1. ê¸°ë³¸ ì •ë³´ ë¡œê¹…
            self.logger.info(f"Input data: FDR={len(fdr_data)}, CRNP={len(crnp_data)}")
            self.logger.info(f"Calibration period: {cal_start.date()} to {cal_end.date()}")
            
            # 2. CRNP ì¼ë³„ í‰ê·  ê³„ì‚° (ê°„ë‹¨í•˜ê²Œ)
            crnp_data_copy = crnp_data.copy()
            crnp_data_copy['date'] = crnp_data_copy['timestamp'].dt.date
            
            # í•„ìˆ˜ ì»¬ëŸ¼ë§Œ ì„ íƒ
            if 'total_corrected_neutrons' not in crnp_data_copy.columns:
                self.logger.error("total_corrected_neutrons column missing!")
                return pd.DataFrame()
                
            daily_crnp = crnp_data_copy.groupby('date')['total_corrected_neutrons'].mean().reset_index()
            self.logger.info(f"Daily CRNP created: {len(daily_crnp)} days")
            
            # 3. FDR ë‚ ì§œ í˜•ì‹ í†µì¼
            fdr_data_copy = fdr_data.copy()
            if 'Date' in fdr_data_copy.columns:
                # ì´ë¯¸ date íƒ€ì…ì´ë©´ ê·¸ëŒ€ë¡œ, datetimeì´ë©´ dateë¡œ ë³€í™˜
                if hasattr(fdr_data_copy['Date'].iloc[0], 'date'):
                    fdr_data_copy['Date'] = fdr_data_copy['Date'].dt.date
                self.logger.info(f"FDR date range: {fdr_data_copy['Date'].min()} to {fdr_data_copy['Date'].max()}")
            else:
                self.logger.error("No Date column in FDR data!")
                return pd.DataFrame()
            
            # 4. ë§¤ì¹­ ì‹œë„ (ë§¤ìš° ë‹¨ìˆœí•˜ê²Œ)
            results = []
            matched_days = 0
            failed_days = 0
            
            for single_date in pd.date_range(start=cal_start, end=cal_end, freq='D'):
                date_key = single_date.date()
                
                # CRNP ë°ì´í„°
                crnp_day = daily_crnp[daily_crnp['date'] == date_key]
                if crnp_day.empty:
                    failed_days += 1
                    self.logger.debug(f"No CRNP for {date_key}")
                    continue
                    
                # FDR ë°ì´í„°  
                fdr_day = fdr_data_copy[fdr_data_copy['Date'] == date_key]
                if fdr_day.empty:
                    failed_days += 1
                    self.logger.debug(f"No FDR for {date_key}")
                    continue
                    
                # ê°„ë‹¨í•œ í† ì–‘ìˆ˜ë¶„ í‰ê·  ê³„ì‚° (ê°€ì¤‘í‰ê·  ëŒ€ì‹ )
                if 'theta_v' in fdr_day.columns:
                    valid_theta = fdr_day[(fdr_day['theta_v'] > 0) & (fdr_day['theta_v'] < 1)]
                    
                    if len(valid_theta) > 0:
                        simple_sm = valid_theta['theta_v'].mean()
                        neutron_count = crnp_day.iloc[0]['total_corrected_neutrons']
                        
                        results.append({
                            'date': single_date,
                            'Daily_N': neutron_count,
                            'Field_SM': simple_sm
                        })
                        
                        matched_days += 1
                        self.logger.debug(f"âœ… {date_key}: N={neutron_count:.1f}, SM={simple_sm:.3f}")
                    else:
                        failed_days += 1
                        self.logger.debug(f"âŒ {date_key}: No valid theta_v")
                else:
                    failed_days += 1
                    self.logger.debug(f"âŒ {date_key}: No theta_v column")
            
            # 5. ê²°ê³¼ ì •ë¦¬
            matched_df = pd.DataFrame(results)
            
            self.logger.info(f"Matching summary: {matched_days} success, {failed_days} failed")
            self.logger.log_data_summary("Matched_Daily", len(matched_df))
            
            if len(matched_df) == 0:
                self.logger.error("ğŸš¨ CRITICAL: Still no matches!")
                self.logger.error("Final debugging:")
                
                # ë‚ ì§œë³„ ìƒì„¸ ë¶„ì„
                sample_date = cal_start.date()
                sample_crnp = daily_crnp[daily_crnp['date'] == sample_date]
                sample_fdr = fdr_data_copy[fdr_data_copy['Date'] == sample_date]
                
                self.logger.error(f"  Sample date: {sample_date}")
                self.logger.error(f"  CRNP for sample: {len(sample_crnp)} records")
                self.logger.error(f"  FDR for sample: {len(sample_fdr)} records")
                
                if len(sample_fdr) > 0:
                    theta_stats = sample_fdr['theta_v'].describe()
                    self.logger.error(f"  Sample theta_v stats: {theta_stats.to_dict()}")
            else:
                self.logger.info(f"ğŸ‰ SUCCESS: {len(matched_df)} daily records matched!")
                
            return matched_df
            
    def _calculate_weighted_soil_moisture(self, fdr_data: pd.DataFrame, 
                                        crnp_data: pd.Series, geo_info: Dict) -> Optional[float]:
        """ê°€ì¤‘í‰ê·  ì§€ì  í† ì–‘ìˆ˜ë¶„ ê³„ì‚°"""
        
        try:
            # ê¹Šì´ë³„ í† ì–‘ìˆ˜ë¶„ ë°ì´í„° í•„í„°ë§
            depth_mask = fdr_data['FDR_depth'].isin(self.depths)
            fdr_filtered = fdr_data[depth_mask]
            
            if fdr_filtered.empty:
                return None
                
            # IDë³„ë¡œ í”„ë¡œíŒŒì¼ ìƒì„±
            fdr_filtered['ID'] = (fdr_filtered['latitude'].astype(str) + '_' + 
                                fdr_filtered['longitude'].astype(str))
            
            # ê°€ì¤‘í‰ê·  ê³„ì‚°
            if self.weighting_method == "Schron_2017":
                field_sm, _ = crnpy.nrad_weight(
                    abs_humidity=crnp_data['abs_humidity'],
                    theta_v=fdr_filtered['theta_v'],
                    distances=fdr_filtered['distance_from_station'],
                    depths=fdr_filtered['FDR_depth'],
                    profiles=fdr_filtered['ID'],
                    rhob=self.bulk_density,
                    p=crnp_data['Pa'],
                    method="Schron_2017"
                )
            else:
                # ê¸°ë³¸ ê°€ì¤‘í‰ê·  (Kohli_2015)
                field_sm, _ = crnpy.nrad_weight(
                    abs_humidity=crnp_data['abs_humidity'],
                    theta_v=fdr_filtered['theta_v'],
                    distances=fdr_filtered['distance_from_station'],
                    depths=fdr_filtered['FDR_depth'],
                    rhob=self.bulk_density,
                    method="Kohli_2015"
                )
                
            return field_sm
            
        except Exception as e:
            self.logger.debug(f"Failed to calculate weighted soil moisture: {e}")
            return None
            
    def _optimize_N0(self, matched_data: pd.DataFrame) -> Dict[str, Any]:
        """N0 ìµœì í™” - API ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•ìœ¼ë¡œ ìˆ˜ì •"""
        
        with ProcessTimer(self.logger, "N0 Optimization"):
            
            if len(matched_data) == 0:
                raise ValueError("No matched data available for optimization")
                
            # ê²©ììˆ˜ ê³„ì‚°
            if self.lattice_water is None:
                self.lattice_water = crnpy.lattice_water(clay_content=self.clay_content)
                
            # ëª©ì í•¨ìˆ˜ ì •ì˜ (RMSE ìµœì†Œí™”) - API ìˆ˜ì •
            def objective(N0):
                try:
                    # âœ… ì˜¬ë°”ë¥¸ API ì‚¬ìš©ë²•: ì²« ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜ë¡œ ì¤‘ì„±ì ì¹´ìš´íŠ¸ ì „ë‹¬
                    crnp_sm = crnpy.counts_to_vwc(
                        matched_data['Daily_N'],  # ì²« ë²ˆì§¸ ìœ„ì¹˜ ë§¤ê°œë³€ìˆ˜
                        N0=N0[0], 
                        bulk_density=self.bulk_density, 
                        Wlat=self.lattice_water, 
                        Wsoc=0.01
                    )
                    
                    # NaN ê°’ ì œê±°
                    valid_mask = ~(np.isnan(crnp_sm) | np.isnan(matched_data['Field_SM']))
                    if valid_mask.sum() == 0:
                        return 1e6  # í° ê°’ ë°˜í™˜
                        
                    crnp_clean = crnp_sm[valid_mask]
                    field_clean = matched_data['Field_SM'].values[valid_mask]
                    
                    rmse = np.sqrt(np.mean((crnp_clean - field_clean) ** 2))
                    return rmse
                    
                except Exception as e:
                    self.logger.debug(f"Objective function error: {e}")
                    return 1e6
                    
            # ìµœì í™” ì‹¤í–‰
            self.logger.info(f"Starting N0 optimization (method: {self.optimization_method})")
            
            result = minimize(
                objective, 
                x0=[self.initial_N0], 
                method=self.optimization_method,
                bounds=[(500, 3000)]  # N0 ë²”ìœ„ ì œí•œ
            )
            
            N0_optimized = result.x[0]
            final_rmse = result.fun
            
            # ìµœì í™” ê²°ê³¼ ê²€ì¦ - API ìˆ˜ì •
            optimized_sm = crnpy.counts_to_vwc(
                matched_data['Daily_N'],  # ì²« ë²ˆì§¸ ìœ„ì¹˜ ë§¤ê°œë³€ìˆ˜
                N0=N0_optimized, 
                bulk_density=self.bulk_density, 
                Wlat=self.lattice_water, 
                Wsoc=0.01
            )
            
            # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            valid_mask = ~(np.isnan(optimized_sm) | np.isnan(matched_data['Field_SM']))
            crnp_clean = optimized_sm[valid_mask]
            field_clean = matched_data['Field_SM'].values[valid_mask]
            
            metrics = self._calculate_performance_metrics(field_clean, crnp_clean)
            
            optimization_result = {
                'N0_optimized': N0_optimized,
                'optimization_success': result.success,
                'final_rmse': final_rmse,
                'metrics': metrics,
                'matched_data_count': len(matched_data),
                'valid_data_count': valid_mask.sum()
            }
            
            self.logger.log_calibration_result(N0_optimized, metrics)
            
            return optimization_result
            
    def _calculate_performance_metrics(self, observed: np.ndarray, 
                                     predicted: np.ndarray) -> Dict[str, float]:
        """ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        
        if len(observed) == 0 or len(predicted) == 0:
            return {}
            
        try:
            # RÂ²
            ss_res = np.sum((observed - predicted) ** 2)
            ss_tot = np.sum((observed - np.mean(observed)) ** 2)
            r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
            
            # RMSE
            rmse = np.sqrt(np.mean((observed - predicted) ** 2))
            
            # MAE
            mae = np.mean(np.abs(observed - predicted))
            
            # NSE (Nash-Sutcliffe Efficiency)
            nse = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
            
            # Bias
            bias = np.mean(predicted - observed)
            
            return {
                'R2': r2,
                'RMSE': rmse,
                'MAE': mae,
                'NSE': nse,
                'Bias': bias,
                'n_samples': len(observed)
            }
            
        except Exception as e:
            self.logger.error(f"Error calculating metrics: {e}")
            return {}
            
    def _create_calibration_result(self, optimization_result: Dict, 
                                 corrected_crnp: pd.DataFrame,
                                 cal_start: datetime, cal_end: datetime) -> Dict[str, Any]:
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ìƒì„±"""
        
        # ì°¸ì¡°ê°’ë“¤ ê³„ì‚°
        reference_values = self.neutron_corrector.calculate_reference_values(
            corrected_crnp, cal_start, cal_end
        )
        
        # ê´€ì¸¡ì†Œ ì •ë³´
        station_info = self.station_config.get('coordinates', {})
        
        calibration_result = {
            'station_id': self.station_config['station_info']['id'],
            'calibration_period': {
                'start': cal_start.isoformat(),
                'end': cal_end.isoformat()
            },
            'coordinates': {
                'lat': station_info.get('latitude'),
                'lon': station_info.get('longitude')
            },
            'N0_rdt': optimization_result['N0_optimized'],
            'Pref': reference_values.get('Pref'),
            'Aref': reference_values.get('Aref'),
            'Iref': reference_values.get('Iref'),
            'clay_content': self.clay_content,
            'soil_bulk_density': self.bulk_density,
            'lattice_water': self.lattice_water,
            'optimization': {
                'method': self.optimization_method,
                'success': optimization_result['optimization_success'],
                'final_rmse': optimization_result['final_rmse'],
                'matched_data_count': optimization_result['matched_data_count']
            },
            'performance_metrics': optimization_result['metrics'],
            'settings': {
                'weighting_method': self.weighting_method,
                'reference_depths': self.depths,
                'corrections_enabled': self.neutron_corrector.corrections_enabled,
                'neutron_monitor': self.neutron_corrector.neutron_monitor
            },
            'timestamp': datetime.now().isoformat()
        }
        
        return calibration_result
        
    def _save_calibration_results(self, calibration_result: Dict, output_dir: str) -> None:
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ì €ì¥"""
        
        import os
        from pathlib import Path
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        station_id = calibration_result['station_id']
        
        # 1. JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì „ì²´ ê²°ê³¼)
        json_file = output_path / f"{station_id}_calibration_result.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(calibration_result, f, indent=2, ensure_ascii=False)
            
        # 2. Excel í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ë§¤ê°œë³€ìˆ˜ë§Œ)
        params_data = {
            'Parameter': ['lat', 'lon', 'N0_rdt', 'Pref', 'Aref', 'Iref', 'clay_content', 'soil_bulk_density'],
            'Value': [
                calibration_result['coordinates']['lat'],
                calibration_result['coordinates']['lon'],
                calibration_result['N0_rdt'],
                calibration_result['Pref'],
                calibration_result['Aref'],
                calibration_result['Iref'],
                calibration_result['clay_content'],
                calibration_result['soil_bulk_density']
            ]
        }
        
        params_df = pd.DataFrame(params_data)
        excel_file = output_path / f"{station_id}_Parameters.xlsx"
        params_df.to_excel(excel_file, index=False)
        
        self.logger.log_file_operation("save", str(json_file), "success")
        self.logger.log_file_operation("save", str(excel_file), "success")
        
    def _load_geo_info(self) -> Dict:
        """ì§€ë¦¬ì •ë³´ ë¡œë“œ"""
        from ..core.config_manager import ConfigManager
        
        config_manager = ConfigManager()
        geo_info = config_manager.load_geo_info_from_yaml(self.station_config)
        
        return geo_info


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    from ..core.logger import setup_logger
    
    # í…ŒìŠ¤íŠ¸ìš© ì„¤ì •
    test_station_config = {
        'station_info': {'id': 'HC'},
        'coordinates': {'latitude': 37.7049111, 'longitude': 128.0316412},
        'soil_properties': {'bulk_density': 1.44, 'clay_content': 0.35},
        'calibration': {'neutron_monitor': 'ATHN', 'utc_offset': 9}
    }
    
    test_processing_config = {
        'calibration': {
            'weighting_method': 'Schron_2017',
            'optimization_method': 'Nelder-Mead',
            'initial_N0': 1000,
            'reference_depths': [10, 30, 60]
        },
        'corrections': {
            'incoming_flux': True,
            'pressure': True,
            'humidity': True,
            'biomass': False
        }
    }
    
    # CalibrationEngine í…ŒìŠ¤íŠ¸
    logger = setup_logger("CalibrationEngine_Test")
    engine = CalibrationEngine(test_station_config, test_processing_config, logger)
    
    print("âœ… CalibrationEngine êµ¬í˜„ ì™„ë£Œ!")
    print("ì£¼ìš” ê¸°ëŠ¥:")
    print("  - ì¤‘ì„±ì ë³´ì • ì ìš©")
    print("  - ì§€ì  í† ì–‘ìˆ˜ë¶„ ê°€ì¤‘í‰ê·  ê³„ì‚°")
    print("  - N0 ìµœì í™”")
    print("  - ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°")
    print("  - ê²°ê³¼ ì €ì¥ (JSON + Excel)")