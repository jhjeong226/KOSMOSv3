# src/calibration/calibration_engine.py

import pandas as pd
import numpy as np
import crnpy
from scipy.optimize import minimize
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
import json

from ..core.logger import CRNPLogger, ProcessTimer
from ..utils.file_handler import FileHandler
from .neutron_correction import NeutronCorrector


class CalibrationEngine:
    """CRNP ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ë‹´ë‹¹í•˜ëŠ” ì—”ì§„ í´ë˜ìŠ¤ - ìˆ˜ì •ëœ ë²„ì „"""
    
    def __init__(self, station_config: Dict, processing_config: Dict, 
                 logger: Optional[CRNPLogger] = None):
        self.station_config = station_config
        self.processing_config = processing_config
        self.logger = logger or CRNPLogger("CalibrationEngine")
        
        # ì¢…ì† ëª¨ë“ˆ ì´ˆê¸°í™”
        self.file_handler = FileHandler(self.logger)
        self.neutron_corrector = NeutronCorrector(station_config, processing_config, self.logger)
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì •
        self.calibration_config = self.processing_config.get('calibration', {})
        self.depths = self.calibration_config.get('reference_depths', [10, 30, 60])
        self.weighting_method = self.calibration_config.get('weighting_method', 'Schron_2017')
        self.optimization_method = self.calibration_config.get('optimization_method', 'Nelder-Mead')
        self.initial_N0 = self.calibration_config.get('initial_N0', 1000)
        
        # í† ì–‘ íŠ¹ì„±
        soil_props = self.station_config.get('soil_properties', {})
        self.bulk_density = soil_props.get('bulk_density', 1.44)
        self.clay_content = soil_props.get('clay_content', 0.35)
        self.lattice_water = None  # ìë™ ê³„ì‚°
        
    def run_calibration(self, calibration_start: str, calibration_end: str,
                       fdr_data_path: str, crnp_data_path: str,
                       output_dir: str) -> Dict[str, Any]:
        """ì „ì²´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ - í–¥ìƒëœ ì§„ë‹¨ í¬í•¨"""
        
        with ProcessTimer(self.logger, "CRNP Calibration",
                         period=f"{calibration_start} to {calibration_end}"):
            
            try:
                # 1. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê¸°ê°„ ì„¤ì •
                cal_start = pd.to_datetime(calibration_start)
                cal_end = pd.to_datetime(calibration_end)
                
                # 2. ë°ì´í„° ë¡œë“œ
                fdr_data, crnp_data = self._load_calibration_data(
                    fdr_data_path, crnp_data_path, cal_start, cal_end
                )
                
                # 3. ì¤‘ì„±ì ë³´ì • ì ìš©
                corrected_crnp = self._apply_neutron_corrections(crnp_data)
                
                # 4. ì§€ë¦¬ì •ë³´ ë¡œë“œ
                geo_info = self._load_geo_info()
                
                # 5. í–¥ìƒëœ ì¼ë³„ ë°ì´í„° ë§¤ì¹­ (ê°€ì¤‘í‰ê·  ì ìš©)
                matched_data = self._match_daily_data_enhanced(
                    fdr_data, corrected_crnp, geo_info, cal_start, cal_end
                )
                
                # 6. N0 ìµœì í™”
                optimization_result = self._optimize_N0_enhanced(matched_data)
                
                # 7. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ìƒì„±
                calibration_result = self._create_calibration_result(
                    optimization_result, corrected_crnp, cal_start, cal_end
                )
                
                # 8. ì§„ë‹¨ ë°ì´í„° ë° ì‹œê°í™” ìƒì„±
                self._generate_calibration_diagnostics(
                    matched_data, optimization_result, output_dir
                )
                
                # 9. ê²°ê³¼ ì €ì¥
                self._save_calibration_results(calibration_result, output_dir)
                
                self.logger.info(f"Calibration completed successfully. N0 = {calibration_result['N0_rdt']:.2f}")
                return calibration_result
                
            except Exception as e:
                self.logger.log_error_with_context(e, "Calibration process")
                raise
                
    def _load_calibration_data(self, fdr_path: str, crnp_path: str,
                              cal_start: datetime, cal_end: datetime) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ"""
        
        with ProcessTimer(self.logger, "Loading calibration data"):
            
            # FDR ë°ì´í„° ë¡œë“œ
            self.logger.info(f"Loading FDR data from {fdr_path}")
            fdr_data = pd.read_excel(fdr_path)
            
            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            if 'Date' in fdr_data.columns:
                fdr_data['Date'] = pd.to_datetime(fdr_data['Date'])
            else:
                raise ValueError("Date column not found in FDR data")
                
            # CRNP ë°ì´í„° ë¡œë“œ
            self.logger.info(f"Loading CRNP data from {crnp_path}")
            crnp_data = pd.read_excel(crnp_path)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì»¬ëŸ¼ í™•ì¸ ë° ì²˜ë¦¬
            if 'timestamp' in crnp_data.columns:
                pass  # ì´ë¯¸ ìˆìŒ
            elif 'Timestamp' in crnp_data.columns:
                crnp_data['timestamp'] = pd.to_datetime(crnp_data['Timestamp'], errors='coerce')
            else:
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ íƒ€ì„ìŠ¤íƒ¬í”„ì¼ ê°€ëŠ¥ì„±
                first_col = crnp_data.columns[0]
                crnp_data['timestamp'] = pd.to_datetime(crnp_data[first_col], errors='coerce')
                self.logger.warning(f"Using first column as timestamp: {first_col}")
            
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§
            fdr_mask = (fdr_data['Date'] >= cal_start) & (fdr_data['Date'] <= cal_end)
            crnp_mask = (crnp_data['timestamp'] >= cal_start) & (crnp_data['timestamp'] <= cal_end)
            
            fdr_filtered = fdr_data[fdr_mask].copy()
            crnp_filtered = crnp_data[crnp_mask].copy()
            
            self.logger.log_data_summary("FDR_Calibration", len(fdr_filtered))
            self.logger.log_data_summary("CRNP_Calibration", len(crnp_filtered))
            
            return fdr_filtered, crnp_filtered
            
    def _apply_neutron_corrections(self, crnp_data: pd.DataFrame) -> pd.DataFrame:
        """ì¤‘ì„±ì ë³´ì • ì ìš©"""
        
        with ProcessTimer(self.logger, "Applying neutron corrections"):
            
            # ì›ì‹œ ì¤‘ì„±ì ì¹´ìš´íŠ¸ ì„¤ì •
            crnp_data['total_raw_counts'] = crnp_data['N_counts']
            
            # ì¤‘ì„±ì ë³´ì • ì ìš©
            corrected_data = self.neutron_corrector.apply_corrections(crnp_data)
            
            # ì´ìƒê°’ ì œê±°
            cleaned_data = self.neutron_corrector.remove_outliers(
                corrected_data, 'total_corrected_neutrons', threshold=3.0
            )
            
            return cleaned_data
            
    def _match_daily_data_enhanced(self, fdr_data: pd.DataFrame, crnp_data: pd.DataFrame,
                                geo_info: Dict, cal_start: datetime, cal_end: datetime) -> pd.DataFrame:
        """í–¥ìƒëœ ì¼ë³„ ë°ì´í„° ë§¤ì¹­ - crnpy ê°€ì¤‘í‰ê·  ì‚¬ìš© (pandas ê²½ê³  ìˆ˜ì •)"""
        
        with ProcessTimer(self.logger, "Enhanced daily data matching"):
            
            # 1. CRNP ì¼ë³„ í‰ê·  ê³„ì‚°
            crnp_data_copy = crnp_data.copy()
            crnp_data_copy['date'] = crnp_data_copy['timestamp'].dt.date
            
            daily_crnp = crnp_data_copy.groupby('date').agg({
                'total_corrected_neutrons': 'mean',
                'abs_humidity': 'mean',
                'Pa': 'mean'
            }).reset_index()
            
            self.logger.info(f"Daily CRNP data: {len(daily_crnp)} days")
            
            # 2. FDR ë°ì´í„° ë‚ ì§œ ì²˜ë¦¬
            fdr_data_copy = fdr_data.copy()
            fdr_data_copy['Date'] = pd.to_datetime(fdr_data_copy['Date'])
            
            results = []
            matched_days = 0
            failed_days = 0
            
            # 3. ì¼ë³„ ë§¤ì¹­ ë° ê°€ì¤‘í‰ê·  ê³„ì‚°
            for single_date in pd.date_range(start=cal_start, end=cal_end, freq='D'):
                date_key = single_date.date()
                
                # CRNP ë°ì´í„°
                crnp_day = daily_crnp[daily_crnp['date'] == date_key]
                if crnp_day.empty:
                    failed_days += 1
                    continue
                    
                # FDR ë°ì´í„°
                fdr_day = fdr_data_copy[fdr_data_copy['Date'].dt.date == date_key]
                if fdr_day.empty:
                    failed_days += 1
                    continue
                
                # ìœ íš¨í•œ FDR ë°ì´í„° í•„í„°ë§ - .copy() ì¶”ê°€ë¡œ pandas ê²½ê³  í•´ê²°
                valid_fdr = fdr_day[
                    (fdr_day['theta_v'].notna()) & 
                    (fdr_day['theta_v'] > 0) & 
                    (fdr_day['theta_v'] < 1) &
                    (fdr_day['FDR_depth'].isin(self.depths))
                ].copy()  # ğŸ”§ .copy() ì¶”ê°€í•˜ì—¬ SettingWithCopyWarning í•´ê²°
                
                if len(valid_fdr) == 0:
                    failed_days += 1
                    continue
                
                # crnpy ê°€ì¤‘í‰ê·  ê³„ì‚°
                try:
                    # í”„ë¡œíŒŒì¼ ID ìƒì„± - ì´ì œ ê²½ê³  ì—†ì´ ì•ˆì „í•˜ê²Œ í• ë‹¹ ê°€ëŠ¥
                    valid_fdr['profile_id'] = (
                        valid_fdr['latitude'].astype(str) + '_' + 
                        valid_fdr['longitude'].astype(str)
                    )
                    
                    crnp_day_data = crnp_day.iloc[0]
                    
                    # crnpy ê°€ì¤‘í‰ê·  ê³„ì‚°
                    if self.weighting_method == "Schron_2017":
                        field_sm, weights = crnpy.nrad_weight(
                            abs_humidity=crnp_day_data['abs_humidity'],
                            theta_v=valid_fdr['theta_v'].values,
                            distances=valid_fdr['distance_from_station'].values,
                            depths=valid_fdr['FDR_depth'].values,
                            profiles=valid_fdr['profile_id'].values,
                            rhob=self.bulk_density,
                            p=crnp_day_data['Pa'],
                            method="Schron_2017"
                        )
                    else:
                        # Kohli_2015 ë°©ë²•
                        field_sm, weights = crnpy.nrad_weight(
                            abs_humidity=crnp_day_data['abs_humidity'],
                            theta_v=valid_fdr['theta_v'].values,
                            distances=valid_fdr['distance_from_station'].values,
                            depths=valid_fdr['FDR_depth'].values,
                            rhob=self.bulk_density,
                            method="Kohli_2015"
                        )
                    
                    # ê²°ê³¼ ì €ì¥
                    results.append({
                        'date': single_date,
                        'Daily_N': crnp_day_data['total_corrected_neutrons'],
                        'Field_SM': field_sm,
                        'Simple_SM': valid_fdr['theta_v'].mean(),  # ë¹„êµìš© ë‹¨ìˆœ í‰ê· 
                        'N_sensors': len(valid_fdr),
                        'abs_humidity': crnp_day_data['abs_humidity'],
                        'pressure': crnp_day_data['Pa']
                    })
                    
                    matched_days += 1
                    self.logger.debug(f"âœ… {date_key}: N={crnp_day_data['total_corrected_neutrons']:.1f}, "
                                    f"Weighted_SM={field_sm:.3f}, Simple_SM={valid_fdr['theta_v'].mean():.3f}")
                    
                except Exception as e:
                    self.logger.debug(f"âŒ {date_key}: Weighting failed - {e}")
                    # ê°€ì¤‘í‰ê·  ì‹¤íŒ¨ì‹œ ë‹¨ìˆœ í‰ê·  ì‚¬ìš©
                    simple_sm = valid_fdr['theta_v'].mean()
                    results.append({
                        'date': single_date,
                        'Daily_N': crnp_day_data['total_corrected_neutrons'],
                        'Field_SM': simple_sm,
                        'Simple_SM': simple_sm,
                        'N_sensors': len(valid_fdr),
                        'abs_humidity': crnp_day_data['abs_humidity'],
                        'pressure': crnp_day_data['Pa']
                    })
                    matched_days += 1
                    failed_days += 1  # ê°€ì¤‘í‰ê·  ì‹¤íŒ¨ë¡œ ì¹´ìš´íŠ¸
            
            # ê²°ê³¼ ì •ë¦¬
            matched_df = pd.DataFrame(results)
            
            self.logger.info(f"Enhanced matching: {matched_days} matched, {failed_days} failed")
            self.logger.log_data_summary("Enhanced_Matched", len(matched_df))
            
            if len(matched_df) > 0:
                self.logger.info(f"Field SM range: {matched_df['Field_SM'].min():.3f} ~ {matched_df['Field_SM'].max():.3f}")
                self.logger.info(f"Neutron range: {matched_df['Daily_N'].min():.1f} ~ {matched_df['Daily_N'].max():.1f}")
                
                # ë³€ë™ì„± í™•ì¸
                sm_std = matched_df['Field_SM'].std()
                neutron_std = matched_df['Daily_N'].std()
                self.logger.info(f"Field SM std: {sm_std:.4f}, Neutron std: {neutron_std:.1f}")
                
                if sm_std < 0.01:
                    self.logger.warning("âš ï¸ Field SM variability is very low - may affect calibration quality")
                    
            return matched_df
            
    def _optimize_N0_enhanced(self, matched_data: pd.DataFrame) -> Dict[str, Any]:
        """í–¥ìƒëœ N0 ìµœì í™”"""
        
        with ProcessTimer(self.logger, "Enhanced N0 Optimization"):
            
            if len(matched_data) == 0:
                raise ValueError("No matched data available for optimization")
                
            # ê²©ììˆ˜ ê³„ì‚°
            if self.lattice_water is None:
                self.lattice_water = crnpy.lattice_water(clay_content=self.clay_content)
                
            self.logger.info(f"Optimization parameters:")
            self.logger.info(f"  Data points: {len(matched_data)}")
            self.logger.info(f"  Bulk density: {self.bulk_density}")
            self.logger.info(f"  Lattice water: {self.lattice_water:.4f}")
            self.logger.info(f"  Field SM range: {matched_data['Field_SM'].min():.3f} - {matched_data['Field_SM'].max():.3f}")
            self.logger.info(f"  Neutron range: {matched_data['Daily_N'].min():.1f} - {matched_data['Daily_N'].max():.1f}")
            
            # ë¨¼ì € ì—¬ëŸ¬ N0 ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
            test_N0_values = np.linspace(500, 3000, 21)  # 500ë¶€í„° 3000ê¹Œì§€ 21ê°œ ê°’
            best_rmse = float('inf')
            best_N0_initial = self.initial_N0
            
            self.logger.info("Testing N0 values:")
            for N0_test in test_N0_values:
                try:
                    vwc_test = crnpy.counts_to_vwc(
                        matched_data['Daily_N'],
                        N0=N0_test,
                        bulk_density=self.bulk_density,
                        Wlat=self.lattice_water,
                        Wsoc=0.01
                    )
                    
                    # ìœ íš¨í•œ ê°’ë§Œ ì„ íƒ
                    valid_mask = ~np.isnan(vwc_test) & (vwc_test >= 0) & (vwc_test <= 1)
                    if valid_mask.sum() > 0:
                        rmse_test = np.sqrt(np.mean((vwc_test[valid_mask] - matched_data['Field_SM'].values[valid_mask]) ** 2))
                        
                        if rmse_test < best_rmse:
                            best_rmse = rmse_test
                            best_N0_initial = N0_test
                            
                        self.logger.debug(f"  N0={N0_test:.0f}: RMSE={rmse_test:.4f}")
                    
                except Exception:
                    continue
                    
            self.logger.info(f"Best initial N0: {best_N0_initial:.0f} (RMSE: {best_rmse:.4f})")
            
            # ëª©ì í•¨ìˆ˜ ì •ì˜
            def objective(N0):
                try:
                    vwc = crnpy.counts_to_vwc(
                        matched_data['Daily_N'],
                        N0=N0[0],
                        bulk_density=self.bulk_density,
                        Wlat=self.lattice_water,
                        Wsoc=0.01
                    )
                    
                    # ìœ íš¨ì„± ê²€ì‚¬
                    if np.any(np.isnan(vwc)) or np.any(vwc < 0) or np.any(vwc > 1):
                        return 1e6
                        
                    # RMSE ê³„ì‚°
                    rmse = np.sqrt(np.mean((vwc - matched_data['Field_SM']) ** 2))
                    return rmse
                    
                except Exception:
                    return 1e6
                    
            # ìµœì í™” ì‹¤í–‰ (ë” ì¢‹ì€ ì´ˆê¸°ê°’ ì‚¬ìš©)
            self.logger.info(f"Starting optimization from N0={best_N0_initial:.0f}")
            
            result = minimize(
                objective,
                x0=[best_N0_initial],
                method=self.optimization_method,
                bounds=[(500, 3000)]
            )
            
            N0_optimized = result.x[0]
            final_rmse = result.fun
            
            # ìµœì í™” ê²°ê³¼ ê³„ì‚°
            optimized_vwc = crnpy.counts_to_vwc(
                matched_data['Daily_N'],
                N0=N0_optimized,
                bulk_density=self.bulk_density,
                Wlat=self.lattice_water,
                Wsoc=0.01
            )
            
            # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            metrics = self._calculate_performance_metrics_robust(
                matched_data['Field_SM'].values, optimized_vwc
            )
            
            # ë””ë²„ê¹… ë°ì´í„° ìƒì„±
            debug_data = matched_data.copy()
            debug_data['CRNP_VWC'] = optimized_vwc
            debug_data['Residuals'] = optimized_vwc - matched_data['Field_SM']
            debug_data['N0_used'] = N0_optimized
            
            optimization_result = {
                'N0_optimized': N0_optimized,
                'optimization_success': result.success,
                'final_rmse': final_rmse,
                'metrics': metrics,
                'matched_data_count': len(matched_data),
                'debug_data': debug_data,
                'initial_test_rmse': best_rmse,
                'initial_test_N0': best_N0_initial
            }
            
            self.logger.log_calibration_result(N0_optimized, metrics)
            
            return optimization_result
            
    def _calculate_performance_metrics_robust(self, observed: np.ndarray, 
                                            predicted: np.ndarray) -> Dict[str, float]:
        """ê°•ê±´í•œ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° - RÂ² ê³„ì‚° ë¬¸ì œ ì™„ì „ í•´ê²°"""
        
        if len(observed) == 0 or len(predicted) == 0:
            return {'R2': 0, 'RMSE': 1, 'MAE': 1, 'NSE': 0, 'Bias': 0, 'Correlation': 0, 'n_samples': 0}
            
        try:
            # ê¸°ë³¸ í†µê³„
            rmse = np.sqrt(np.mean((observed - predicted) ** 2))
            mae = np.mean(np.abs(observed - predicted))
            bias = np.mean(predicted - observed)
            
            # Pearson ìƒê´€ê³„ìˆ˜ (ê°€ì¥ ì•ˆì •ì )
            if len(observed) > 1:
                correlation = np.corrcoef(observed, predicted)[0, 1]
                if np.isnan(correlation):
                    correlation = 0.0
            else:
                correlation = 0.0
                
            # ê´€ì¸¡ê°’ ë³€ë™ì„± í™•ì¸
            obs_std = np.std(observed)
            obs_var = np.var(observed)
            obs_mean = np.mean(observed)
            pred_std = np.std(predicted)
            
            self.logger.info(f"Performance calculation details:")
            self.logger.info(f"  Observed: mean={obs_mean:.6f}, std={obs_std:.6f}, var={obs_var:.6f}")
            self.logger.info(f"  Predicted: mean={np.mean(predicted):.6f}, std={pred_std:.6f}")
            self.logger.info(f"  Correlation: {correlation:.6f}")
            self.logger.info(f"  RMSE: {rmse:.6f}, MAE: {mae:.6f}")
            
            # RÂ² ê³„ì‚° ë°©ë²• ê²°ì •
            r2 = 0.0
            method_used = "none"
            
            # 1. ì¶©ë¶„í•œ ë³€ë™ì„±ì´ ìˆëŠ” ê²½ìš° (í‘œì¤€í¸ì°¨ > 0.01)
            if obs_std > 0.01:
                # ì „í†µì ì¸ RÂ² ê³„ì‚°
                ss_res = np.sum((observed - predicted) ** 2)
                ss_tot = np.sum((observed - obs_mean) ** 2)
                
                if ss_tot > 1e-10:  # ë¶„ëª¨ê°€ ì¶©ë¶„íˆ í° ê²½ìš°
                    r2_traditional = 1 - (ss_res / ss_tot)
                    
                    # í•©ë¦¬ì ì¸ ë²”ìœ„ì¸ì§€ í™•ì¸ (-2 ~ 1)
                    if -2 <= r2_traditional <= 1:
                        r2 = r2_traditional
                        method_used = "traditional"
                        self.logger.info(f"  Traditional RÂ²: {r2:.6f} (SS_res={ss_res:.6f}, SS_tot={ss_tot:.6f})")
                    else:
                        # ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ìƒê´€ê³„ìˆ˜ ì œê³± ì‚¬ìš©
                        r2 = max(0, correlation ** 2)
                        method_used = "correlation_squared_fallback"
                        self.logger.warning(f"  Traditional RÂ² out of range ({r2_traditional:.6f}), using correlationÂ²")
                else:
                    # ë¶„ëª¨ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ìƒê´€ê³„ìˆ˜ ì œê³± ì‚¬ìš©
                    r2 = max(0, correlation ** 2)
                    method_used = "correlation_squared_small_denominator"
                    self.logger.warning(f"  SS_tot too small ({ss_tot:.10f}), using correlationÂ²")
                    
            # 2. ë³€ë™ì„±ì´ ì‘ì€ ê²½ìš° (0.005 < std <= 0.01)
            elif obs_std > 0.005:
                # ìƒê´€ê³„ìˆ˜ ì œê³±ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
                r2 = max(0, correlation ** 2)
                method_used = "correlation_squared_moderate_var"
                self.logger.info(f"  Moderate variability, using correlationÂ²: {r2:.6f}")
                
            # 3. ë³€ë™ì„±ì´ ë§¤ìš° ì‘ì€ ê²½ìš° (std <= 0.005)
            else:
                # ìƒëŒ€ ì˜¤ì°¨ ê¸°ë°˜ í‰ê°€
                if abs(obs_mean) > 1e-10:
                    relative_rmse = rmse / abs(obs_mean)
                    
                    # ìƒëŒ€ ì˜¤ì°¨ê°€ 10% ì´ë‚´ë©´ ì–‘í˜¸
                    if relative_rmse <= 0.1:
                        r2 = max(0, 1 - relative_rmse * 5)  # ìµœëŒ€ 0.5
                    elif relative_rmse <= 0.2:
                        r2 = max(0, 1 - relative_rmse * 2.5)  # ìµœëŒ€ 0.5
                    else:
                        r2 = 0
                        
                    method_used = "relative_error_based"
                    self.logger.warning(f"  Very low variability, using relative error method: {r2:.6f} (rel_rmse={relative_rmse:.6f})")
                else:
                    # ê´€ì¸¡ê°’ í‰ê· ì´ 0ì— ê°€ê¹Œìš´ ê²½ìš°
                    r2 = max(0, correlation ** 2) if abs(correlation) > 0.3 else 0
                    method_used = "correlation_near_zero_mean"
                    self.logger.warning(f"  Near-zero observed mean, using correlation if strong: {r2:.6f}")
            
            # NSE ê³„ì‚° (RÂ²ì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬)
            nse = r2
            
            # ê²°ê³¼ ê²€ì¦
            if r2 < 0:
                r2 = 0
                self.logger.warning(f"  Negative RÂ² set to 0")
            elif r2 > 1:
                r2 = 1
                self.logger.warning(f"  RÂ² > 1 set to 1")
                
            self.logger.info(f"  Final RÂ² = {r2:.6f} (method: {method_used})")
            
            # í’ˆì§ˆ ê²½ê³ 
            if obs_std < 0.005:
                self.logger.warning(f"  Very low observed variability may limit calibration quality")
            if abs(correlation) < 0.3:
                self.logger.warning(f"  Weak correlation may indicate poor model fit")
                
            return {
                'R2': float(r2),
                'RMSE': float(rmse),
                'MAE': float(mae),
                'NSE': float(nse),
                'Bias': float(bias),
                'Correlation': float(correlation),
                'n_samples': len(observed),
                'obs_std': float(obs_std),
                'pred_std': float(pred_std),
                'obs_mean': float(obs_mean),
                'pred_mean': float(np.mean(predicted)),
                'method_used': method_used
            }
            
        except Exception as e:
            self.logger.error(f"Error calculating metrics: {e}")
            import traceback
            traceback.print_exc()
            return {
                'R2': 0, 'RMSE': 1, 'MAE': 1, 'NSE': 0, 'Bias': 0, 'Correlation': 0, 
                'n_samples': len(observed), 'method_used': 'error'
            }
            
    def _generate_calibration_diagnostics(self, matched_data: pd.DataFrame, 
                                        optimization_result: Dict, output_dir: str) -> None:
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì§„ë‹¨ ë°ì´í„° ë° ì‹œê°í™” ìƒì„±"""
        
        import matplotlib.pyplot as plt
        import matplotlib.dates as mdates
        from pathlib import Path
        
        try:
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            station_id = self.station_config['station_info']['id']
            debug_data = optimization_result['debug_data']
            
            # 1. ìƒì„¸ ì‹œê°í™” ìƒì„± (ì˜ë¬¸)
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            
            # Time series comparison
            axes[0,0].plot(debug_data['date'], debug_data['Field_SM'], 'bo-', 
                          label='FDR Field SM', markersize=8, linewidth=2)
            axes[0,0].plot(debug_data['date'], debug_data['CRNP_VWC'], 'ro-', 
                          label='CRNP VWC', markersize=8, linewidth=2)
            if 'Simple_SM' in debug_data.columns:
                axes[0,0].plot(debug_data['date'], debug_data['Simple_SM'], 'g^-', 
                              label='Simple Average SM', markersize=6, alpha=0.7)
            axes[0,0].set_xlabel('Date')
            axes[0,0].set_ylabel('Volumetric Water Content')
            axes[0,0].set_title(f'{station_id} - Calibration Time Series')
            axes[0,0].legend()
            axes[0,0].grid(True, alpha=0.3)
            axes[0,0].tick_params(axis='x', rotation=45)
            
            # Scatter plot
            axes[0,1].scatter(debug_data['Field_SM'], debug_data['CRNP_VWC'], 
                             s=120, alpha=0.8, c='blue', edgecolors='black')
            
            # 1:1 line
            min_val = min(debug_data['Field_SM'].min(), debug_data['CRNP_VWC'].min())
            max_val = max(debug_data['Field_SM'].max(), debug_data['CRNP_VWC'].max())
            axes[0,1].plot([min_val, max_val], [min_val, max_val], 'r--', 
                          linewidth=2, label='1:1 Line')
            
            # Best fit line
            z = np.polyfit(debug_data['Field_SM'], debug_data['CRNP_VWC'], 1)
            p = np.poly1d(z)
            axes[0,1].plot(debug_data['Field_SM'], p(debug_data['Field_SM']), 
                          'g-', alpha=0.8, label=f'Best fit (y={z[0]:.2f}x+{z[1]:.3f})')
            
            axes[0,1].set_xlabel('FDR Field SM')
            axes[0,1].set_ylabel('CRNP VWC')
            axes[0,1].set_title('Calibration Scatter Plot')
            axes[0,1].legend()
            axes[0,1].grid(True, alpha=0.3)
            
            # Neutron counts time series
            axes[0,2].plot(debug_data['date'], debug_data['Daily_N'], 'go-', 
                          label='Daily Neutron Counts', markersize=8, linewidth=2)
            axes[0,2].set_xlabel('Date')
            axes[0,2].set_ylabel('Neutron Counts')
            axes[0,2].set_title('Neutron Counts Time Series')
            axes[0,2].legend()
            axes[0,2].grid(True, alpha=0.3)
            axes[0,2].tick_params(axis='x', rotation=45)
            
            # Residuals plot
            axes[1,0].scatter(debug_data['CRNP_VWC'], debug_data['Residuals'], 
                             s=120, alpha=0.8, c='red', edgecolors='black')
            axes[1,0].axhline(y=0, color='k', linestyle='--', linewidth=2)
            axes[1,0].set_xlabel('CRNP VWC')
            axes[1,0].set_ylabel('Residuals (CRNP - FDR)')
            axes[1,0].set_title('Residuals Plot')
            axes[1,0].grid(True, alpha=0.3)
            
            # Residuals time series
            axes[1,1].plot(debug_data['date'], debug_data['Residuals'], 'mo-', 
                          markersize=8, linewidth=2)
            axes[1,1].axhline(y=0, color='k', linestyle='--', linewidth=2)
            axes[1,1].set_xlabel('Date')
            axes[1,1].set_ylabel('Residuals (CRNP - FDR)')
            axes[1,1].set_title('Residuals Time Series')
            axes[1,1].grid(True, alpha=0.3)
            axes[1,1].tick_params(axis='x', rotation=45)
            
            # Performance metrics text
            metrics = optimization_result['metrics']
            metrics_text = f"""Performance Metrics:
RÂ² = {metrics.get('R2', 0):.4f}
RMSE = {metrics.get('RMSE', 0):.4f}
MAE = {metrics.get('MAE', 0):.4f}
Bias = {metrics.get('Bias', 0):.4f}
Correlation = {metrics.get('Correlation', 0):.4f}

Optimization:
N0 = {optimization_result['N0_optimized']:.1f}
Data points = {len(debug_data)}

Data Variability:
FDR std = {metrics.get('obs_std', 0):.4f}
CRNP std = {metrics.get('pred_std', 0):.4f}"""
            
            axes[1,2].text(0.1, 0.9, metrics_text, transform=axes[1,2].transAxes, 
                          fontsize=11, verticalalignment='top', 
                          bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
            axes[1,2].set_xlim(0, 1)
            axes[1,2].set_ylim(0, 1)
            axes[1,2].axis('off')
            axes[1,2].set_title('Calibration Results Summary')
            
            plt.tight_layout()
            
            # ê·¸ë˜í”„ ì €ì¥
            plot_file = output_path / f"{station_id}_calibration_diagnostics.png"
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.log_file_operation("save", str(plot_file), "success")
            
            # 2. ê°„ë‹¨í•œ ë¹„êµ ê·¸ë˜í”„ (ìš”ì²­ì‚¬í•­)
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
            
            # Time series comparison
            ax1.plot(debug_data['date'], debug_data['Field_SM'], 'bo-', 
                    label='FDR Field SM', markersize=6, linewidth=2)
            ax1.plot(debug_data['date'], debug_data['CRNP_VWC'], 'ro-', 
                    label='CRNP VWC', markersize=6, linewidth=2)
            ax1.set_xlabel('Date')
            ax1.set_ylabel('Volumetric Water Content')
            ax1.set_title(f'{station_id} Calibration Period - Time Series Comparison')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            ax1.tick_params(axis='x', rotation=45)
            
            # Scatter plot
            ax2.scatter(debug_data['Field_SM'], debug_data['CRNP_VWC'], 
                       s=100, alpha=0.8, c='blue')
            ax2.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='1:1 Line')
            ax2.set_xlabel('FDR Field SM')
            ax2.set_ylabel('CRNP VWC')
            ax2.set_title(f'Scatter Plot (RÂ² = {metrics.get("R2", 0):.3f})')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            comparison_plot_file = output_path / f"{station_id}_calibration_comparison.png"
            plt.savefig(comparison_plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.log_file_operation("save", str(comparison_plot_file), "success")
            
            # 3. ë””ë²„ê¹… ë°ì´í„° Excel ì €ì¥
            debug_excel_file = output_path / f"{station_id}_calibration_debug_data.xlsx"
            with pd.ExcelWriter(debug_excel_file, engine='openpyxl') as writer:
                debug_data.to_excel(writer, sheet_name='Calibration_Data', index=False)
                
                # ìš”ì•½ ì‹œíŠ¸
                summary_data = {
                    'Metric': ['RÂ²', 'RMSE', 'MAE', 'Bias', 'Correlation', 'N0', 'Data Points',
                              'FDR Std', 'CRNP Std', 'FDR Mean', 'CRNP Mean'],
                    'Value': [
                        metrics.get('R2', 0),
                        metrics.get('RMSE', 0),
                        metrics.get('MAE', 0), 
                        metrics.get('Bias', 0),
                        metrics.get('Correlation', 0),
                        optimization_result['N0_optimized'],
                        len(debug_data),
                        metrics.get('obs_std', 0),
                        metrics.get('pred_std', 0),
                        debug_data['Field_SM'].mean(),
                        debug_data['CRNP_VWC'].mean()
                    ]
                }
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='Summary', index=False)
                
            self.logger.log_file_operation("save", str(debug_excel_file), "success")
            
        except Exception as e:
            self.logger.warning(f"Could not generate calibration diagnostics: {e}")
            
    def _create_calibration_result(self, optimization_result: Dict, 
                                 corrected_crnp: pd.DataFrame,
                                 cal_start: datetime, cal_end: datetime) -> Dict[str, Any]:
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ìƒì„±"""
        
        # ì°¸ì¡°ê°’ë“¤ ê³„ì‚°
        reference_values = self.neutron_corrector.calculate_reference_values(
            corrected_crnp, cal_start, cal_end
        )
        
        # ê´€ì¸¡ì†Œ ì •ë³´
        station_info = self.station_config.get('coordinates', {})
        
        calibration_result = {
            'station_id': self.station_config['station_info']['id'],
            'calibration_period': {
                'start': cal_start.isoformat(),
                'end': cal_end.isoformat()
            },
            'coordinates': {
                'lat': station_info.get('latitude'),
                'lon': station_info.get('longitude')
            },
            'N0_rdt': optimization_result['N0_optimized'],
            'Pref': reference_values.get('Pref'),
            'Aref': reference_values.get('Aref'),
            'Iref': reference_values.get('Iref'),
            'clay_content': self.clay_content,
            'soil_bulk_density': self.bulk_density,
            'lattice_water': self.lattice_water,
            'optimization': {
                'method': self.optimization_method,
                'success': optimization_result['optimization_success'],
                'final_rmse': optimization_result['final_rmse'],
                'matched_data_count': optimization_result['matched_data_count'],
                'initial_test_rmse': optimization_result.get('initial_test_rmse'),
                'initial_test_N0': optimization_result.get('initial_test_N0')
            },
            'performance_metrics': optimization_result['metrics'],
            'settings': {
                'weighting_method': self.weighting_method,
                'reference_depths': self.depths,
                'corrections_enabled': self.neutron_corrector.corrections_enabled,
                'neutron_monitor': self.neutron_corrector.neutron_monitor
            },
            'timestamp': datetime.now().isoformat()
        }
        
        return calibration_result
        
    def _save_calibration_results(self, calibration_result: Dict, output_dir: str) -> None:
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ì €ì¥"""
        
        from pathlib import Path
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        station_id = calibration_result['station_id']
        
        # JSON ì €ì¥
        json_file = output_path / f"{station_id}_calibration_result.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(calibration_result, f, indent=2, ensure_ascii=False)
        
        # ë§¤ê°œë³€ìˆ˜ Excel ì €ì¥
        params_data = {
            'Parameter': ['lat', 'lon', 'N0_rdt', 'Pref', 'Aref', 'Iref', 'clay_content', 'soil_bulk_density'],
            'Value': [
                calibration_result['coordinates']['lat'],
                calibration_result['coordinates']['lon'],
                calibration_result['N0_rdt'],
                calibration_result['Pref'],
                calibration_result['Aref'],
                calibration_result['Iref'],
                calibration_result['clay_content'],
                calibration_result['soil_bulk_density']
            ]
        }
        params_df = pd.DataFrame(params_data)
        excel_file = output_path / f"{station_id}_Parameters.xlsx"
        params_df.to_excel(excel_file, index=False)
        
        self.logger.log_file_operation("save", str(json_file), "success")
        self.logger.log_file_operation("save", str(excel_file), "success")
        
    def _load_geo_info(self) -> Dict:
        """ì§€ë¦¬ì •ë³´ ë¡œë“œ"""
        from ..core.config_manager import ConfigManager
        
        config_manager = ConfigManager()
        geo_info = config_manager.load_geo_info_from_yaml(self.station_config)
        
        return geo_info