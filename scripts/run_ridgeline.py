#!/usr/bin/env python3
"""
run_ridgeline.py

ë²”ìš© Ridgeline Plot ìƒì„±ê¸°
ì „ì²˜ë¦¬ëœ í† ì–‘ìˆ˜ë¶„ ë°ì´í„°ë¡œë¶€í„° ridgeline plot ìƒì„±

íŠ¹ì§•:
- ê²¨ìš¸ì²  ë°ì´í„° ìë™ ì œì™¸ (11, 12, 1, 2, 3ì›”)
- ê´€ì¸¡ì†Œ ì»¬ëŸ¼ ìë™ ê°ì§€
- ê¹Šì´ ìë™ ê°ì§€ (10cm, 30cm, 60cm ë“± ìœ ì—° ì§€ì›)
- Average ë¶„í¬ ìë™ ì¶”ê°€ (ëª¨ë“  ê´€ì¸¡ì†Œ ë°ì´í„° í•©ì§‘í•©)
- ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ ë° ê²½ë¡œ ì§€ì›

ì‚¬ìš©ë²•:
    python script/run_ridgeline.py --station HC
    python script/run_ridgeline.py --station PC --input-dir data/input
    python script/run_ridgeline.py --station HC --depths 10cm 20cm --output-dir plots
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import argparse
import sys
from pathlib import Path
import warnings
import json
warnings.filterwarnings('ignore')

# ì„¤ì •
plt.style.use('default')
sns.set_palette("husl")

class RidgelineGenerator:
    """ë²”ìš© Ridgeline Plot ìƒì„±ê¸°"""
    
    def __init__(self, station_id: str, base_dir: str = "data"):
        self.station_id = station_id
        self.base_dir = Path(base_dir)
        
        # ê²½ë¡œ ì„¤ì •
        self.output_dir = self.base_dir / "output" / station_id
        self.input_dir = self.base_dir / "input"
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.station_columns = {}
        self.processed_data = {}
        
        print(f"ğŸ”§ ì´ˆê¸°í™”: ê´€ì¸¡ì†Œ {station_id}")
        print(f"ğŸ“‚ ë°ì´í„° ë””ë ‰í† ë¦¬: {self.output_dir}")
        print(f"ğŸ“‚ ì…ë ¥ ë””ë ‰í† ë¦¬: {self.input_dir}")
        print(f"ğŸ“Š ê¸°ë³¸ ì¶œë ¥ ê²½ë¡œ: {self.output_dir}/visualization/")
    
    def find_fdr_files(self, depths: list = None) -> dict:
        """FDR íŒŒì¼ ìë™ íƒìƒ‰ ë° ê¹Šì´ ìë™ ê°ì§€"""
        
        found_files = {}
        auto_detected_depths = set()
        
        # ê°€ëŠ¥í•œ íŒŒì¼ íŒ¨í„´ë“¤
        possible_patterns = [
            # ì „ì²˜ë¦¬ëœ íŒŒì¼ë“¤
            f"{self.station_id}_FDR_daily_depths.xlsx",
            f"{self.station_id}_FDR_input.xlsx", 
            f"{self.station_id}_fdr_data.xlsx",
            # ì›ë³¸ íŒŒì¼ë“¤
            "HC_FDR_daily_depths.xlsx",
            "FDR_daily_depths.xlsx",
            f"{self.station_id}_daily_depths.xlsx",
        ]
        
        # íƒìƒ‰ ê²½ë¡œë“¤
        search_paths = [
            self.output_dir / "preprocessed",
            self.output_dir,
            self.input_dir,
            Path("."),  # í˜„ì¬ ë””ë ‰í† ë¦¬
            Path("data"),
        ]
        
        for search_path in search_paths:
            if not search_path.exists():
                continue
                
            for pattern in possible_patterns:
                file_path = search_path / pattern
                
                if file_path.exists():
                    try:
                        # Excel íŒŒì¼ ì‹œíŠ¸ í™•ì¸
                        xl_file = pd.ExcelFile(file_path)
                        available_sheets = xl_file.sheet_names
                        print(f"ğŸ“‹ ë°œê²¬ëœ íŒŒì¼: {file_path}")
                        print(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œíŠ¸: {available_sheets}")
                        
                        # ê¹Šì´ ì‹œíŠ¸ ìë™ ê°ì§€
                        detected_depths = self._detect_depth_sheets(available_sheets)
                        auto_detected_depths.update(detected_depths)
                        
                        # ìš”ì²­ëœ ê¹Šì´ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ê¹Šì´ë§Œ, ì—†ìœ¼ë©´ ê°ì§€ëœ ëª¨ë“  ê¹Šì´
                        target_depths = depths if depths else list(detected_depths)
                        
                        for depth in target_depths:
                            # ì •í™•í•œ ë§¤ì¹­ ë¨¼ì € ì‹œë„
                            if depth in available_sheets:
                                found_files[depth] = file_path
                                print(f"âœ… {depth} ë°ì´í„° ë°œê²¬: {file_path}")
                            else:
                                # ìœ ì‚¬í•œ ì‹œíŠ¸ëª… ì°¾ê¸°
                                depth_num = ''.join(filter(str.isdigit, depth))
                                for sheet in available_sheets:
                                    sheet_num = ''.join(filter(str.isdigit, sheet))
                                    if depth_num and sheet_num and depth_num == sheet_num:
                                        found_files[depth] = file_path
                                        print(f"âœ… {depth} ë°ì´í„° ë§¤ì¹­: {file_path} (ì‹œíŠ¸: {sheet})")
                                        break
                        
                        if found_files:
                            break
                            
                    except Exception as e:
                        print(f"âš ï¸ íŒŒì¼ í™•ì¸ ì‹¤íŒ¨ {file_path}: {e}")
                        continue
            
            if found_files:
                break
        
        if not found_files:
            if auto_detected_depths:
                print(f"ğŸ’¡ ê°ì§€ëœ ê¹Šì´ë“¤: {sorted(auto_detected_depths)}")
                print("ğŸ’¡ ì˜ˆì‹œ: --depths 10cm 30cm 60cm")
            print(f"âŒ FDR ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ“ ë‹¤ìŒ ìœ„ì¹˜ë“¤ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:")
            for path in search_paths:
                print(f"   - {path}")
        
        return found_files
    
    def _detect_depth_sheets(self, sheet_names: list) -> set:
        """ì‹œíŠ¸ëª…ìœ¼ë¡œë¶€í„° ê¹Šì´ ì •ë³´ ìë™ ê°ì§€"""
        
        detected_depths = set()
        
        # íŒ¨í„´ 1: "10cm", "20cm", "30cm" í˜•íƒœ
        for sheet in sheet_names:
            sheet_lower = sheet.lower()
            if 'cm' in sheet_lower:
                # ìˆ«ì + cm íŒ¨í„´ ì¶”ì¶œ
                import re
                match = re.search(r'(\d+)cm', sheet_lower)
                if match:
                    depth_num = match.group(1)
                    detected_depths.add(f"{depth_num}cm")
        
        # íŒ¨í„´ 2: ìˆœìˆ˜ ìˆ«ì ì‹œíŠ¸ëª… ("10", "20", "30")
        for sheet in sheet_names:
            if sheet.isdigit():
                detected_depths.add(f"{sheet}cm")
        
        # íŒ¨í„´ 3: "depth_10", "layer_30" ë“±
        for sheet in sheet_names:
            sheet_lower = sheet.lower()
            if any(keyword in sheet_lower for keyword in ['depth', 'layer', 'level']):
                import re
                match = re.search(r'(\d+)', sheet)
                if match:
                    depth_num = match.group(1)
                    detected_depths.add(f"{depth_num}cm")
        
        return detected_depths
    
    def detect_station_columns(self, df: pd.DataFrame) -> dict:
        """ê´€ì¸¡ì†Œ ì»¬ëŸ¼ ìë™ ê°ì§€"""
        
        # Date ê´€ë ¨ ì»¬ëŸ¼ ì œì™¸
        exclude_patterns = ['date', 'time', 'timestamp', 'year', 'month', 'day']
        potential_cols = []
        
        for col in df.columns:
            col_lower = str(col).lower()
            if not any(pattern in col_lower for pattern in exclude_patterns):
                # ìˆ˜ì¹˜ ë°ì´í„°ì¸ì§€ í™•ì¸
                try:
                    numeric_data = pd.to_numeric(df[col], errors='coerce')
                    valid_ratio = numeric_data.notna().sum() / len(df)
                    
                    if valid_ratio > 0.5:  # 50% ì´ìƒì´ ìœ íš¨í•œ ìˆ˜ì¹˜
                        # í† ì–‘ìˆ˜ë¶„ ë²”ìœ„ì¸ì§€ í™•ì¸ (0.01 ~ 1.0)
                        valid_values = numeric_data.dropna()
                        if len(valid_values) > 0:
                            if (valid_values.min() >= 0.001 and valid_values.max() <= 1.0):
                                potential_cols.append(col)
                except:
                    continue
        
        print(f"ğŸ” ê°ì§€ëœ ê´€ì¸¡ì†Œ ì»¬ëŸ¼: {potential_cols}")
        
        # ì»¬ëŸ¼ëª…ì„ ê´€ì¸¡ì†Œëª…ìœ¼ë¡œ ë§¤í•‘ (ê¸°ë³¸ì ìœ¼ë¡œ ì»¬ëŸ¼ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        station_mapping = {}
        for col in potential_cols:
            # ì»¬ëŸ¼ëª… ì •ë¦¬ (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
            clean_name = str(col).strip().replace(' ', '_')
            station_mapping[col] = clean_name
        
        return station_mapping
    
    def load_soil_moisture_data(self, file_path: Path, depth: str) -> pd.DataFrame:
        """í† ì–‘ìˆ˜ë¶„ ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬"""
        
        try:
            # ì‹œíŠ¸ëª… ê²°ì •
            xl_file = pd.ExcelFile(file_path)
            sheet_name = depth
            
            # ì •í™•í•œ ì‹œíŠ¸ëª…ì´ ì—†ìœ¼ë©´ ìœ ì‚¬í•œ ì‹œíŠ¸ ì°¾ê¸°
            if depth not in xl_file.sheet_names:
                depth_num = depth.replace('cm', '')
                for sheet in xl_file.sheet_names:
                    if depth_num in sheet or depth in sheet:
                        sheet_name = sheet
                        break
                else:
                    print(f"âš ï¸ {depth}ì— í•´ë‹¹í•˜ëŠ” ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return pd.DataFrame()
            
            # ë°ì´í„° ë¡œë“œ
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            
            print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")
            
            # Date ì»¬ëŸ¼ ì²˜ë¦¬
            date_cols = [col for col in df.columns if 'date' in str(col).lower()]
            date_index = None
            
            if date_cols:
                try:
                    df[date_cols[0]] = pd.to_datetime(df[date_cols[0]])
                    df.set_index(date_cols[0], inplace=True)
                    date_index = df.index
                    print(f"ğŸ“… ë‚ ì§œ ë²”ìœ„: {date_index.min().strftime('%Y-%m-%d')} ~ {date_index.max().strftime('%Y-%m-%d')}")
                except:
                    print("âš ï¸ ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬ ì‹¤íŒ¨, ì›”ë³„ í•„í„°ë§ ê±´ë„ˆëœ€")
                    date_index = None
            
            # ê²¨ìš¸ì²  ë°ì´í„° ì œì™¸ (11, 12, 1, 2, 3ì›”)
            if date_index is not None:
                winter_months = [11, 12, 1, 2, 3]
                original_length = len(df)
                
                # ê²¨ìš¸ì² ì´ ì•„ë‹Œ ë°ì´í„°ë§Œ ì„ íƒ
                growing_season_mask = ~date_index.month.isin(winter_months)
                df = df[growing_season_mask]
                
                filtered_length = len(df)
                excluded_count = original_length - filtered_length
                
                print(f"â„ï¸ ê²¨ìš¸ì²  ë°ì´í„° ì œì™¸: {excluded_count:,}ê°œ ì œê±° ({excluded_count/original_length*100:.1f}%)")
                print(f"ğŸŒ± ìƒìœ¡ê¸°ê°„ ë°ì´í„°: {filtered_length:,}ê°œ ({filtered_length/original_length*100:.1f}%)")
                
                if filtered_length > 0:
                    remaining_months = sorted(df.index.month.unique())
                    print(f"ğŸ“… í¬í•¨ëœ ì›”: {remaining_months}")
            
            # ê´€ì¸¡ì†Œ ì»¬ëŸ¼ ìë™ ê°ì§€
            station_mapping = self.detect_station_columns(df)
            
            if not station_mapping:
                print(f"âŒ {depth} ë°ì´í„°ì—ì„œ ìœ íš¨í•œ ê´€ì¸¡ì†Œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            # Long formatìœ¼ë¡œ ë³€í™˜
            data_list = []
            
            for col_name, station_name in station_mapping.items():
                values = pd.to_numeric(df[col_name], errors='coerce').dropna()
                
                # í˜„ì‹¤ì ì¸ í† ì–‘ìˆ˜ë¶„ ë²”ìœ„ í•„í„°ë§
                values = values[(values >= 0.01) & (values <= 0.8)]
                
                if len(values) > 20:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­
                    for value in values:
                        data_list.append({
                            'Station': station_name,
                            'VWC': value
                        })
                    
                    print(f"âœ… {station_name}: {len(values)} ë°ì´í„° í¬ì¸íŠ¸")
            
            if not data_list:
                print(f"âš ï¸ {depth} ë°ì´í„°ì—ì„œ ìœ íš¨í•œ í† ì–‘ìˆ˜ë¶„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            result_df = pd.DataFrame(data_list)
            
            # Average ë¶„í¬ ì¶”ê°€ (ëª¨ë“  ê´€ì¸¡ì†Œ ë°ì´í„°ì˜ í•©ì§‘í•©)
            if len(result_df) > 100:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ
                all_values = result_df['VWC'].values
                
                average_df = pd.DataFrame({
                    'Station': ['Average'] * len(all_values),
                    'VWC': all_values
                })
                
                result_df = pd.concat([result_df, average_df], ignore_index=True)
                print(f"ğŸ“Š ì „ì²´ í‰ê·  ë¶„í¬ ì¶”ê°€: {len(all_values)} í¬ì¸íŠ¸")
            
            print(f"âœ… {depth} ìµœì¢… ë°ì´í„°: {len(result_df)} í¬ì¸íŠ¸, {result_df['Station'].nunique()} ê´€ì¸¡ì†Œ")
            
            return result_df
            
        except Exception as e:
            print(f"âŒ {depth} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def create_ridgeline_plot(self, df: pd.DataFrame, depth: str, output_dir: Path) -> Path:
        """Ridgeline plot ìƒì„±"""
        
        if df.empty:
            print(f"âš ï¸ {depth} ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ í”Œë¡¯ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ê´€ì¸¡ì†Œ ìˆœì„œ (í‰ê·  ê¸°ì¤€ ì •ë ¬, AverageëŠ” ë§¨ ì•„ë˜ë¡œ)
        station_means = df.groupby('Station')['VWC'].mean().sort_values(ascending=False)
        station_order = station_means.index.tolist()
        
        # Averageë¥¼ ë§¨ ì•„ë˜ë¡œ
        if 'Average' in station_order:
            station_order.remove('Average')
            station_order.append('Average')
        
        n_stations = len(station_order)
        
        # ìƒ‰ìƒ ì„¤ì •
        colors = sns.color_palette("viridis", n_stations)
        
        # ê·¸ë˜í”„ ì„¤ì • (1:1.5 ë¹„ìœ¨)
        base_width = max(8, min(12, n_stations * 0.8))  # ê¸°ë³¸ ë„ˆë¹„
        figsize = (base_width, base_width * 1.5)  # 1:1.5 ë¹„ìœ¨ ìœ ì§€
        
        fig, axes = plt.subplots(n_stations, 1, figsize=figsize, sharex=True)
        
        if n_stations == 1:
            axes = [axes]
        
        # ì „ì²´ ë°ì´í„° ë²”ìœ„
        x_min, x_max = df['VWC'].quantile([0.005, 0.995])
        x_range = np.linspace(x_min, x_max, 100)
        
        # ê° ê´€ì¸¡ì†Œë³„ ridgeline ê·¸ë¦¬ê¸°
        for i, station in enumerate(station_order):
            ax = axes[i]
            
            # í•´ë‹¹ ê´€ì¸¡ì†Œ ë°ì´í„°
            station_data = df[df['Station'] == station]['VWC'].values
            
            # ì»¤ë„ ë°€ë„ ì¶”ì •
            try:
                kde = stats.gaussian_kde(station_data)
                kde.set_bandwidth(kde.factor * 0.8)  # ì•½ê°„ ë” ë¶€ë“œëŸ½ê²Œ
                kde_values = kde(x_range)
            except:
                # KDE ì‹¤íŒ¨ì‹œ íˆìŠ¤í† ê·¸ë¨ ì‚¬ìš©
                hist, bins = np.histogram(station_data, bins=30, density=True, 
                                        range=(x_min, x_max))
                bin_centers = (bins[:-1] + bins[1:]) / 2
                kde_values = np.interp(x_range, bin_centers, hist)
            
            # ìƒ‰ìƒ ì„ íƒ
            if station == 'Average':
                color = '#e74c3c'  # ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ê°•ì¡°
                alpha = 0.8
            else:
                color = colors[i]
                alpha = 0.7
            
            # Ridgeline ê·¸ë¦¬ê¸°
            ax.fill_between(x_range, 0, kde_values, 
                           color=color, alpha=alpha, linewidth=0)
            ax.plot(x_range, kde_values, color=color, linewidth=1.5)
            
            # í‰ê· ì„ 
            mean_val = np.mean(station_data)
            max_density = np.max(kde_values)
            ax.vlines(mean_val, 0, max_density, 
                     colors='white', linewidth=2, alpha=0.9)
            
            # ì¶• ì„¤ì •
            ax.set_xlim(x_min, x_max)
            ax.set_ylim(0, None)
            ax.set_yticks([])
            
            # ê´€ì¸¡ì†Œëª… í‘œì‹œ
            ax.text(0.01, 0.8, station, transform=ax.transAxes,
                   fontsize=11, fontweight='bold',
                   bbox=dict(boxstyle='round,pad=0.3',
                            facecolor='white', alpha=0.8, edgecolor='none'))
            
            # í†µê³„ ì •ë³´
            stats_text = f"Î¼={mean_val:.3f}\nÏƒ={np.std(station_data):.3f}\nn={len(station_data):,}"
            ax.text(0.99, 0.8, stats_text, transform=ax.transAxes,
                   fontsize=9, ha='right',
                   bbox=dict(boxstyle='round,pad=0.3',
                            facecolor='white', alpha=0.7, edgecolor='none'))
            
            # ì¶• ìŠ¤íƒ€ì¼ë§
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
            ax.spines['left'].set_visible(False)
            
            if i < n_stations - 1:
                ax.spines['bottom'].set_visible(False)
                ax.set_xticks([])
            else:
                ax.spines['bottom'].set_color('#cccccc')
                ax.tick_params(colors='#666666')
        
        # ì œëª© ë° ë¼ë²¨
        title = f'{self.station_id} - {depth} Soil Moisture Ridge Plot (Growing Season)'
        fig.suptitle(title, fontsize=16, fontweight='bold', y=0.95)
        
        axes[-1].set_xlabel('Volumetric Water Content (mÂ³/mÂ³)',
                           fontsize=12, color='#333333')
        
        # ë ˆì´ì•„ì›ƒ ì¡°ì •
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0)
        
        # ë°°ê²½ìƒ‰ ì„¤ì •
        fig.patch.set_facecolor('white')
        
        # ì €ì¥
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"{self.station_id}_ridgeline_{depth}.png"
        
        fig.savefig(output_file, dpi=300, bbox_inches='tight',
                   facecolor='white', edgecolor='none')
        
        print(f"âœ… ì €ì¥ë¨: {output_file}")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        plt.close(fig)
        
        return output_file
    
    def print_summary_stats(self, df: pd.DataFrame, depth: str):
        """ìš”ì•½ í†µê³„ ì¶œë ¥"""
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š {self.station_id} - {depth} SUMMARY STATISTICS (Growing Season)")
        print('='*60)
        print("â„ï¸ ê²¨ìš¸ì²  ë°ì´í„° ì œì™¸ë¨ (11, 12, 1, 2, 3ì›”)")
        print('-'*60)
        
        summary = df.groupby('Station')['VWC'].agg([
            'count', 'mean', 'std', 'min', 'max'
        ]).round(3)
        
        summary['range'] = (summary['max'] - summary['min']).round(3)
        summary['cv%'] = (summary['std'] / summary['mean'] * 100).round(1)
        
        # ì •ë ¬
        summary = summary.sort_values('mean', ascending=False)
        
        print(summary)
        
        print(f"\nğŸ“ˆ Overall Statistics (Growing Season Only):")
        print(f"   Total data points: {len(df):,}")
        print(f"   Stations: {df['Station'].nunique() - (1 if 'Average' in df['Station'].values else 0)} + Average")
        print(f"   Overall mean: {df[df['Station'] != 'Average']['VWC'].mean():.3f} mÂ³/mÂ³")
        print(f"   Overall std: {df[df['Station'] != 'Average']['VWC'].std():.3f}")
        print(f"   Data range: {df['VWC'].min():.3f} - {df['VWC'].max():.3f} mÂ³/mÂ³")
        print(f"   Coefficient of variation: {(df[df['Station'] != 'Average']['VWC'].std()/df[df['Station'] != 'Average']['VWC'].mean()*100):.1f}%")
    
    def run(self, depths: list = None, output_dir: str = None):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        
        if output_dir is None:
            # ê¸°ë³¸ ì¶œë ¥ ê²½ë¡œ: data/output/{station_id}/visualization/
            output_dir = self.output_dir / "visualization"
        else:
            output_dir = Path(output_dir)
        
        print(f"\nğŸš€ {self.station_id} ê´€ì¸¡ì†Œ Ridgeline Plot ìƒì„± ì‹œì‘")
        if depths:
            print(f"ğŸ“‹ ì§€ì •ëœ ê¹Šì´: {depths}")
        else:
            print(f"ğŸ“‹ ìë™ ê¹Šì´ ê°ì§€ ëª¨ë“œ")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        
        # FDR íŒŒì¼ íƒìƒ‰ (ê¹Šì´ ìë™ ê°ì§€ í¬í•¨)
        fdr_files = self.find_fdr_files(depths)
        
        if not fdr_files:
            print("âŒ ì²˜ë¦¬í•  FDR íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("\nğŸ’¡ íŒíŠ¸:")
            print("   1. ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
            print("   2. FDR íŒŒì¼ì´ ë‹¤ìŒ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
            print(f"      - {self.output_dir}/preprocessed/")
            print(f"      - {self.input_dir}/")
            return False
        
        # ì‹¤ì œ ì²˜ë¦¬í•  ê¹Šì´ ëª©ë¡
        actual_depths = list(fdr_files.keys())
        print(f"ğŸ“Š ì²˜ë¦¬ ì˜ˆì • ê¹Šì´: {actual_depths}")
        
        success_count = 0
        
        # ê° ê¹Šì´ë³„ ì²˜ë¦¬
        for depth in actual_depths:
            print(f"\nğŸ” {depth} ì²˜ë¦¬ ì¤‘...")
            
            # ë°ì´í„° ë¡œë“œ
            df = self.load_soil_moisture_data(fdr_files[depth], depth)
            
            if df.empty:
                print(f"âš ï¸ {depth} ë°ì´í„°ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            # ìš”ì•½ í†µê³„
            self.print_summary_stats(df, depth)
            
            # Ridgeline plot ìƒì„±
            output_file = self.create_ridgeline_plot(df, depth, output_dir)
            
            if output_file:
                success_count += 1
                self.processed_data[depth] = df
        
        print(f"\nğŸ‰ ì™„ë£Œ! {success_count}/{len(actual_depths)} ê°œ í”Œë¡¯ ìƒì„± ì„±ê³µ")
        
        if success_count > 0:
            print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
            print(f"ğŸ“Š ìƒì„±ëœ íŒŒì¼ë“¤:")
            for depth in actual_depths:
                if depth in self.processed_data:
                    filename = f"{self.station_id}_ridgeline_{depth}.png"
                    print(f"   âœ… {filename}")
            return True
        else:
            return False

def main():
    """ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤"""
    
    parser = argparse.ArgumentParser(
        description="ë²”ìš© Ridgeline Plot ìƒì„±ê¸°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python script/run_ridgeline.py --station HC                    # ìë™ ê¹Šì´ ê°ì§€
  python script/run_ridgeline.py --station PC --depths 10cm 30cm 60cm
  python script/run_ridgeline.py --station HC --base-dir /path/to/data
  python script/run_ridgeline.py --station MyStation --output-dir ./custom_results
        """
    )
    
    parser.add_argument('--station', '-s', required=True,
                       help='ê´€ì¸¡ì†Œ ID (ì˜ˆ: HC, PC)')
    
    parser.add_argument('--depths', '-d', nargs='+',
                       help='ì²˜ë¦¬í•  ê¹Šì´ë“¤ (ì˜ˆ: 10cm 30cm 60cm). ë¯¸ì§€ì •ì‹œ ìë™ ê°ì§€')
    
    parser.add_argument('--base-dir', '-b', default='data',
                       help='ë°ì´í„° ê¸°ë³¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data)')
    
    parser.add_argument('--output-dir', '-o',
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data/output/{station_id}/visualization/)')
    
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='ìƒì„¸ ì¶œë ¥')
    
    args = parser.parse_args()
    
    if args.verbose:
        print(f"ğŸ”§ ì„¤ì •:")
        print(f"   ê´€ì¸¡ì†Œ: {args.station}")
        print(f"   ê¹Šì´: {args.depths if args.depths else 'ìë™ ê°ì§€'}")
        print(f"   ê¸°ë³¸ ë””ë ‰í† ë¦¬: {args.base_dir}")
        print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output_dir}")
        print(f"   â„ï¸ ê²¨ìš¸ì²  ë°ì´í„° ì œì™¸: 11, 12, 1, 2, 3ì›”")
        print(f"   ğŸ“Š Average ë¶„í¬ í¬í•¨: ëª¨ë“  ê´€ì¸¡ì†Œ ë°ì´í„°ì˜ í•©ì§‘í•©")
    
    try:
        # ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = RidgelineGenerator(args.station, args.base_dir)
        
        # ì‹¤í–‰
        success = generator.run(args.depths, args.output_dir)
        
        if success:
            print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            sys.exit(0)
        else:
            print("\nâŒ ì¼ë¶€ ë˜ëŠ” ëª¨ë“  ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()